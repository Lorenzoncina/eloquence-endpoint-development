services:
  whisper:
    build:
      context: .
      dockerfile: Dockerfile
    image: eloquence-endpoint:latest
    volumes:
      - ./src:/app
    working_dir: /app
    ports:
      - "8080:8080"
    environment:
      - HF_TOKEN=${HF_TOKEN}
      
      # --- THIS IS THE FIX ---
      # Set the complete, static library path.
      # This combines the base image's NVIDIA paths with the CUDA path.
      - LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/lib64
    
    entrypoint: ["python3", "whisper_api_python.py"]
    # entrypoint: ["python3", "openai_woz_api.py"]
    restart: unless-stopped